{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATAP Juxtorpus Notebook\n",
    "This notebook provides a simple workflow for the user to upload, partition and compare their text collections.\n",
    "The workflow consists of three interactive ATAP tools, [**ATAP_corpus_loader**](https://github.com/Australian-Text-Analytics-Platform/atap-corpus-loader), [**ATAP_corpus_slicer**](https://github.com/Australian-Text-Analytics-Platform/atap-corpus-slicer) and [**Juxtorpus**](https://github.com/Sydney-Informatics-Hub/juxtorpus/). \n",
    "The user can upload their text collections as plain text files or spreadsheets, partition data based on versitile conditions, and generate side-to-side comparison between corpus pairs.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "For any questions, feedback, and/or comments about the tool, please contact the Sydney Informatics Hub at [sih.info@sydney.edu.au](mailto:sih.info@sydney.edu.au?subject=[ATAP]%20Juxtorpus%20inquiry).</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Jupyter Notebook User Guide</b> \n",
    "\n",
    "If you are new to Jupyter Notebook, feel free to take a quick look at [this user guide](documents/jupyter-notebook-guide.pdf) for basic information on how to use a notebook.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>ATAP Corpus Loader User Guide</b>\n",
    "    \n",
    "For instructions on how to use the Corpus Loader, please refer to the [Corpus Loader User Guide](documents/Corpus_Loader_User_Guide.pdf). The user guides for the Slicer and Juxtorpus are currently under development.\n",
    "</div>\n",
    "\n",
    "## 1. Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm .ipynb_checkpoints/Juxtorpus-Demo-checkpoint.ipynb\n",
    "\n",
    "from app.JuxVisual import *\n",
    "# from atap_corpus_slicer import CorpusSlicer\n",
    "from atap_corpus_loader import CorpusLoader\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from bokeh.resources import INLINE\n",
    "import bokeh.io\n",
    "\n",
    "bokeh.io.output_notebook(INLINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "pn.extension(\"plotly\")\n",
    "\n",
    "from atap_corpus_timeline import CorpusTimeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "This notebook will allow you to upload text data in one or more text files, each file contains one document. Alternatively, you can also upload multiple texts as an excel or CSV spreadsheet, in which each row is considered as one document ([see example dataset here](data/ADO/qldelection2020_candidate_tweets.csv)). Multiple files can be zipped and uploaded as a single archive file.\n",
    "</div>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The example dataset under *data/ADO/* is a twitter dataset of all Queensland election candidates during 2020, kindly supplied by the [Australian Digital Observatory](https://www.digitalobservatory.net.au/), an LDaCa partner Australian humanities infrastructure.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Execute the next cell to run the [*ATAP corpus loader*](https://github.com/Australian-Text-Analytics-Platform/atap-corpus-loader) *UI* so that you can upload your files and build your corpus following the instructions below. Supported file types are .txt, .csv, .xlsx or a zip archive of these file types.  \n",
    "Once a corpus is successfully built, you can continue with the rest of the notebook to run the Document Similarity Tool with your corpus.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Using the ATAP corpus loader to load your dataset/corpus</b> <br>\n",
    "<td><img src='./documents/img/corpus_loader.png' style='width: 1000px'/></td> <br>\n",
    "In order to use the document similarity tool, the user needs to build their corpus with the ATAP corpus loader. As a brief overview, the steps to use the loader are as follows (Please check the picture above for locations referred by superscript numbers):\n",
    "\n",
    "1. Upload your text files using the file explorer pane on the left<sup>1</sup>. <p>If the pane is not activated, clicking on the folder icon<sup>2</sup> will show you the file explorer pane.\n",
    "Files can be uploaded into any folder by either drag-n-drop or via the upload button<sup>3</sup> <br>\n",
    "Wait until your corpus is uploaded before you return to the notebook and execute the codes.\n",
    "\n",
    "2. Execute the following code cell to run the ATAP Corpus Loader in order to build your corpus from the uploaded files, all supported filetypes will be displayed and can be filtered<sup>4</sup> in the corpus-loader.\n",
    "\n",
    "3. Choose the files in the selector pane<sup>5</sup>, then click the 'Load as corpus' button<sup>6</sup>.  \n",
    "If loading from a spreadsheet with multiple columns, first, select the correct header of the column that contains the text data<sup>7</sup>. Then make sure the required metadata columns are checked<sup>8</sup> with the correct datatype<sup>9</sup> for your corpus.  \n",
    "For example, if one column consists of text, the datatype TEXT is appropriate and no changes are necessary.  \n",
    "If plain text files are loaded, the Corpus Loader also automatically creates and includes the filename as TEXT type metadata.\n",
    "\n",
    "4. Give your corpus a name<sup>10</sup> and click on the button “Build corpus”<sup>11</sup>. Wait until you receive the message “Corpus … built successfully”.   \n",
    "Review your corpus in the Corpus Overview or continue immediately to the next code cell in the notebook.  \n",
    "Refer to the screenshot above for each necessary operation.<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The corpus loader also supports to load a metadata spreadsheet and join with the text data with a column of unique identifier, or using the OniLoader to build a corpus from a public LDaCa collection. All these advanced usage can be found in the [Corpus Loader User Guide](documents/Corpus_Loader_User_Guide.pdf).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora: CorpusLoader = CorpusLoader(root_directory='./', \n",
    "                                     include_meta_loader=True, \n",
    "                                     include_oni_loader=False,\n",
    "                                     run_logger=True)\n",
    "\n",
    "# slicer: CorpusSlicer = CorpusSlicer(corpus_loader=corpora)\n",
    "# slicer\n",
    "\n",
    "timeline: CorpusTimeline = CorpusTimeline(corpus_loader=corpora)\n",
    "timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the word list that you decide to exclude from the analysis in the following line, if you don't have any, leave it as excluded_words = []\n",
    "# Single or double quote the words and delimiter them with comma, like this: excluded_words = ['these', 'are', 'words', 'I', 'definitely', 'want', 'to', 'exclude']\n",
    "excluded_words = []\n",
    "# If you want to include the stopwords pre-defined here: https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/feature_extraction/_stop_words.py\n",
    "# Remove the \"#\" in front of the following line, if there is one. \n",
    "# Otherwise, add a \"#\" in front of the line to not include pre-defined English stopwords.\n",
    "excluded_words.extend(ENGLISH_STOP_WORDS)\n",
    "pn.extension('tabulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jux_dashboard = visualise_jux(corpora, fixed_stopwords=excluded_words)\n",
    "Jux_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
